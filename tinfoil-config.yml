shim-version: v0.2.9@sha256:cab643630f04d4d4d0a02d9d361fdf4a068c228c3f301b3e4d1c3b933310ad14
cvm-version: 0.1.3
ovmf-version: 0.0.2
cpus: 8
memory: 32768

models:
  - name: "llama-free"
    repo: "lambdalabs/Llama-3.3-70B-Instruct-AWQ-4bit@a70257cf10f368114a66115c315def76a1227e26"
    mpk: "06002d4871dbd882fc8b4c385e5181fdd85615e514f4efca3b6b3a3a774a36d2_39785426944_58b5d994-b471-58c9-8058-d224be115e1a"
vllm-args: --quantization awq_marlin --max-model-len 65536 --enable-auto-tool-choice --tool-call-parser llama3_json --chat-template /etc/tinfoil/templates/tool_chat_template_llama3.1_json.jinja

shim:
  listen-port: 443
  upstream-port: 8080
  publish-attestation: false
  tls-challenge: dns
  paths:
    - /v1/chat/completions
    - /metrics
